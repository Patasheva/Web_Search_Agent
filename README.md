# Assistant IA üîé Recherche Web 
Un chatbot simple capable d‚Äôacc√©der √† Internet pour rechercher des informations et g√©n√©rer des r√©ponses pertinentes en s‚Äôappuyant sur des contenus fiables et r√©cents. Il acc√®de au moteur de recherche Google, filtre les pages par mots-cl√©s et par date, extrait un court r√©sum√© de chaque page ainsi que le lien vers la source, puis int√®gre ces informations dans la r√©ponse g√©n√©r√©e.

# Stack technique
- Backend : Python, FastAPI
- Frontend : React
- Web search : SerpAPI

# LLMs open source
- qwen-2.5-72b-instruct (via OpenRouter)
- mistral:7b (en local via Ollama)

# Orchestration 
- LangGraph
- Architecture modulaire

# Pr√©requis
- installer ollama en local (https://ollama.com)
- t√©l√©charger mistral en local: ollama pull mistral:7b
- SERPAPI_API_KEY
- OPENROUTER_API_KEY
  
# Mode local
Terminal 1 (backend): uvicorn main:app --reload
http://localhost:8000
Terminal 2 (frontend): npm start 
http://localhost:3000

# Partie 2 Architecture et d√©ploiement en production 
- D√©ploiement d‚Äôun Agent IA (FastAPI + React) sur Azure avec CI/CD
Pr√©requis :
- Compte GitHub actif
- Projet backend avec main.py, requirements.txt (+ Dockerfile si d√©ploiement via conteneur)
- Projet frontend avec package.json
- Compte Azure actif
- Abonnement active pour App Services
- Groupe de ressources cr√©√© dans Azure

1. Backend (FastAPI)
- Pousser le code sur GitHub
- Cr√©er une Web App sur Azure
(Azure Portal ‚Üí App Services ‚Üí Cr√©er une application Web)
- Choisir pile d‚Äôex√©cution : Python 3.13
- Choisir m√©thode de d√©ploiement : GitHub Actions
- Connecter le repo GitHub (Lien le compte GitHub, Organisation, D√©p√¥t, Branche)
- Configuration automatique:
‚Üí  cr√©e un pipeline CI/CD avec GitHub Actions pour d√©ployer automatiquement √† chaque push
‚Üí installe les d√©pendances √† partir de requirements.txt
‚Üí livre un lien public d‚ÄôAPI 
- Configurer les cl√©s API / variables d‚Äôenvironnement
  (Azure App Settings / GitHub Secrets)
  
2.Frontend (React)
- Pousser le code sur GitHub
- Cr√©er une application web statique
( Azure Portal ‚Üí App Services ‚Üí Cr√©er une application Web statique)
-  Choisis un plan d‚Äôh√©bergement: Free / Standard / Dedicated
- Connecter le repo GitHub : (Lien le compte GitHub, Organisation, D√©p√¥t, Branche)
- Configuration automatique:
‚Üí cr√©e un pipeline CI/CD avec GitHub Actions
‚Üí installe les d√©pendances √† partir de package.json
‚Üí livre un lien public d‚ÄôAPI interface

3. Connexion Frontend ‚Üî Backend

4. Monitoring post-deployment : Azure Monitor pour g√©rer les logs, les metriques, les alertes. 

Co√ªt mensuel : 500 requ√™tes/jour =  25‚Ç¨/mois

# Partie 3 Vision Language Model
Pas de configuration avec GPU 
Pour traiter des documents contenant √† la fois du texte et des √©l√©ments visuels (images, graphiques, sch√©mas) dans un pipeline RAG, on peut convertir chaque page ou bloc du document en image, en extraire le texte, puis g√©n√©rer une requ√™te repr√©sentative (query) pour chaque unit√© de contenu. Ces donn√©es (image, texte, requ√™te) sont stock√©es dans un fichier Parquet structur√©. Ensuite, pour r√©pondre √† une question utilisateur, on transforme ce dataset en une base vectorielle multimodale : on encode √† la fois le texte et l‚Äôimage avec un mod√®le VLM, ce qui permet de faire une recherche s√©mantique efficace sur les documents complexes.

# Optimisations √† r√©aliser :
- Utiliser un moteur d‚Äôindexation vectorielle
- Limiter la longueur du contexte
- Batcher les requ√™tes externes
- Garder la trace des sources
- Optimiser les prompts pour le r√©sum√© et la g√©n√©ration des r√©ponses adapt√©es aux cas concrets
- Cr√©er un syst√®me de gestion des erreurs
- Mettre en place un syst√®me de gestion des limites de taux (rate limiting)
- Ajuster la temp√©rature du LLM 
  
# Demo :
![Demo image](Demo.png)
![Demo test image](Demo_test.png)

